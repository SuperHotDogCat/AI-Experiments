{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCnOp3jBlmCj",
        "outputId": "cc45a2bc-8d65-4303-ae8d-f80b4f0ad0b0"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->pytorch-tabnet) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->pytorch-tabnet) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#df = pd.read_csv(\"train.csv\")\n",
        "#詳しくはここhttps://github.com/dreamquark-ai/tabnet/tree/develop"
      ],
      "metadata": {
        "id": "rw_O_ewZl4Ek"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()"
      ],
      "metadata": {
        "id": "WqS04hZamK-9"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = np.concatenate([data.data, data.target.reshape(20640,1)], axis = 1)"
      ],
      "metadata": {
        "id": "0vqwRBJnmbmk"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, X_test = df[:int(0.8*len(df))], df[int(0.8*len(df)):int(0.9*len(df))],df[int(0.9*len(df)):]"
      ],
      "metadata": {
        "id": "-9zo7kjQnhrr"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unsupervised_model = TabNetPretrainer(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    mask_type='entmax' # \"sparsemax\"\n",
        ")\n",
        "\n",
        "unsupervised_model.fit(\n",
        "    X_train=X_train,\n",
        "    eval_set=[X_valid],\n",
        "    pretraining_ratio=0.8,\n",
        "    max_epochs=500,\n",
        "    patience=35,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMdCC9BYnbAm",
        "outputId": "d62de966-9e38-47d4-9075-93c055ac7c87"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 418.27955| val_0_unsup_loss_numpy: 3633.772705078125|  0:00:02s\n",
            "epoch 1  | loss: 290.70801| val_0_unsup_loss_numpy: 2458.705810546875|  0:00:05s\n",
            "epoch 2  | loss: 138.6288| val_0_unsup_loss_numpy: 2745.99755859375|  0:00:07s\n",
            "epoch 3  | loss: 26.27022| val_0_unsup_loss_numpy: 1885.794677734375|  0:00:10s\n",
            "epoch 4  | loss: 3.8508  | val_0_unsup_loss_numpy: 1768.054931640625|  0:00:13s\n",
            "epoch 5  | loss: 2.18467 | val_0_unsup_loss_numpy: 987.9741821289062|  0:00:15s\n",
            "epoch 6  | loss: 2.03046 | val_0_unsup_loss_numpy: 376.2887878417969|  0:00:18s\n",
            "epoch 7  | loss: 1.62305 | val_0_unsup_loss_numpy: 1765.5413818359375|  0:00:20s\n",
            "epoch 8  | loss: 1.43801 | val_0_unsup_loss_numpy: 582.4559936523438|  0:00:22s\n",
            "epoch 9  | loss: 1.30222 | val_0_unsup_loss_numpy: 440.5889892578125|  0:00:24s\n",
            "epoch 10 | loss: 1.36428 | val_0_unsup_loss_numpy: 377.00537109375|  0:00:26s\n",
            "epoch 11 | loss: 1.29948 | val_0_unsup_loss_numpy: 446.3124694824219|  0:00:27s\n",
            "epoch 12 | loss: 1.2297  | val_0_unsup_loss_numpy: 428.4448547363281|  0:00:29s\n",
            "epoch 13 | loss: 1.28621 | val_0_unsup_loss_numpy: 328.71185302734375|  0:00:32s\n",
            "epoch 14 | loss: 1.22891 | val_0_unsup_loss_numpy: 175.0853729248047|  0:00:33s\n",
            "epoch 15 | loss: 1.30833 | val_0_unsup_loss_numpy: 63.3826904296875|  0:00:34s\n",
            "epoch 16 | loss: 1.2288  | val_0_unsup_loss_numpy: 147.3315887451172|  0:00:35s\n",
            "epoch 17 | loss: 1.1847  | val_0_unsup_loss_numpy: 343.70751953125|  0:00:36s\n",
            "epoch 18 | loss: 1.22475 | val_0_unsup_loss_numpy: 291.22357177734375|  0:00:37s\n",
            "epoch 19 | loss: 1.18258 | val_0_unsup_loss_numpy: 290.52471923828125|  0:00:37s\n",
            "epoch 20 | loss: 1.15859 | val_0_unsup_loss_numpy: 227.31117248535156|  0:00:38s\n",
            "epoch 21 | loss: 1.13617 | val_0_unsup_loss_numpy: 192.2904052734375|  0:00:39s\n",
            "epoch 22 | loss: 1.12781 | val_0_unsup_loss_numpy: 151.19149780273438|  0:00:40s\n",
            "epoch 23 | loss: 1.13482 | val_0_unsup_loss_numpy: 377.0653991699219|  0:00:41s\n",
            "epoch 24 | loss: 1.19498 | val_0_unsup_loss_numpy: 231.07142639160156|  0:00:41s\n",
            "epoch 25 | loss: 1.13542 | val_0_unsup_loss_numpy: 241.50094604492188|  0:00:42s\n",
            "epoch 26 | loss: 1.11362 | val_0_unsup_loss_numpy: 244.9801025390625|  0:00:43s\n",
            "epoch 27 | loss: 1.1114  | val_0_unsup_loss_numpy: 66.29534912109375|  0:00:45s\n",
            "epoch 28 | loss: 1.15189 | val_0_unsup_loss_numpy: 16.94083023071289|  0:00:46s\n",
            "epoch 29 | loss: 1.13505 | val_0_unsup_loss_numpy: 38.26543045043945|  0:00:47s\n",
            "epoch 30 | loss: 1.10681 | val_0_unsup_loss_numpy: 21.606719970703125|  0:00:47s\n",
            "epoch 31 | loss: 1.06104 | val_0_unsup_loss_numpy: 19.39982032775879|  0:00:48s\n",
            "epoch 32 | loss: 1.10645 | val_0_unsup_loss_numpy: 18.440540313720703|  0:00:49s\n",
            "epoch 33 | loss: 1.15113 | val_0_unsup_loss_numpy: 19.466480255126953|  0:00:50s\n",
            "epoch 34 | loss: 1.11177 | val_0_unsup_loss_numpy: 21.470399856567383|  0:00:51s\n",
            "epoch 35 | loss: 1.06604 | val_0_unsup_loss_numpy: 16.963319778442383|  0:00:52s\n",
            "epoch 36 | loss: 1.08473 | val_0_unsup_loss_numpy: 14.224120140075684|  0:00:53s\n",
            "epoch 37 | loss: 1.11607 | val_0_unsup_loss_numpy: 3.9014101028442383|  0:00:54s\n",
            "epoch 38 | loss: 1.06646 | val_0_unsup_loss_numpy: 5.595290184020996|  0:00:54s\n",
            "epoch 39 | loss: 1.05715 | val_0_unsup_loss_numpy: 5.779789924621582|  0:00:55s\n",
            "epoch 40 | loss: 1.06124 | val_0_unsup_loss_numpy: 4.56063985824585|  0:00:56s\n",
            "epoch 41 | loss: 1.07922 | val_0_unsup_loss_numpy: 4.3744001388549805|  0:00:57s\n",
            "epoch 42 | loss: 1.1062  | val_0_unsup_loss_numpy: 3.0925800800323486|  0:00:59s\n",
            "epoch 43 | loss: 1.06357 | val_0_unsup_loss_numpy: 3.871799945831299|  0:01:00s\n",
            "epoch 44 | loss: 1.03647 | val_0_unsup_loss_numpy: 2.7008299827575684|  0:01:00s\n",
            "epoch 45 | loss: 1.06127 | val_0_unsup_loss_numpy: 5.651340007781982|  0:01:01s\n",
            "epoch 46 | loss: 1.05236 | val_0_unsup_loss_numpy: 6.933489799499512|  0:01:02s\n",
            "epoch 47 | loss: 1.04746 | val_0_unsup_loss_numpy: 3.5059900283813477|  0:01:03s\n",
            "epoch 48 | loss: 1.04928 | val_0_unsup_loss_numpy: 2.290750026702881|  0:01:04s\n",
            "epoch 49 | loss: 1.03516 | val_0_unsup_loss_numpy: 2.1278600692749023|  0:01:05s\n",
            "epoch 50 | loss: 1.02029 | val_0_unsup_loss_numpy: 2.4365499019622803|  0:01:05s\n",
            "epoch 51 | loss: 1.1947  | val_0_unsup_loss_numpy: 3.3405799865722656|  0:01:06s\n",
            "epoch 52 | loss: 1.02278 | val_0_unsup_loss_numpy: 5.585619926452637|  0:01:07s\n",
            "epoch 53 | loss: 1.0733  | val_0_unsup_loss_numpy: 3.239300012588501|  0:01:08s\n",
            "epoch 54 | loss: 1.06509 | val_0_unsup_loss_numpy: 2.80253005027771|  0:01:09s\n",
            "epoch 55 | loss: 1.02492 | val_0_unsup_loss_numpy: 2.5763299465179443|  0:01:10s\n",
            "epoch 56 | loss: 1.03431 | val_0_unsup_loss_numpy: 2.8639400005340576|  0:01:12s\n",
            "epoch 57 | loss: 1.03202 | val_0_unsup_loss_numpy: 2.7749900817871094|  0:01:12s\n",
            "epoch 58 | loss: 1.04824 | val_0_unsup_loss_numpy: 3.701240062713623|  0:01:13s\n",
            "epoch 59 | loss: 1.00391 | val_0_unsup_loss_numpy: 4.6531901359558105|  0:01:14s\n",
            "epoch 60 | loss: 1.01985 | val_0_unsup_loss_numpy: 2.994580030441284|  0:01:15s\n",
            "epoch 61 | loss: 1.03355 | val_0_unsup_loss_numpy: 1.9630399942398071|  0:01:16s\n",
            "epoch 62 | loss: 0.99356 | val_0_unsup_loss_numpy: 3.395620107650757|  0:01:17s\n",
            "epoch 63 | loss: 1.00456 | val_0_unsup_loss_numpy: 2.557310104370117|  0:01:18s\n",
            "epoch 64 | loss: 1.00197 | val_0_unsup_loss_numpy: 2.748769998550415|  0:01:19s\n",
            "epoch 65 | loss: 0.99131 | val_0_unsup_loss_numpy: 2.423870086669922|  0:01:20s\n",
            "epoch 66 | loss: 1.01891 | val_0_unsup_loss_numpy: 2.6229300498962402|  0:01:21s\n",
            "epoch 67 | loss: 1.0737  | val_0_unsup_loss_numpy: 2.5844500064849854|  0:01:22s\n",
            "epoch 68 | loss: 0.98201 | val_0_unsup_loss_numpy: 3.430989980697632|  0:01:23s\n",
            "epoch 69 | loss: 1.00502 | val_0_unsup_loss_numpy: 2.1416399478912354|  0:01:24s\n",
            "epoch 70 | loss: 1.03493 | val_0_unsup_loss_numpy: 4.345290184020996|  0:01:25s\n",
            "epoch 71 | loss: 1.00503 | val_0_unsup_loss_numpy: 3.3721399307250977|  0:01:26s\n",
            "epoch 72 | loss: 1.02255 | val_0_unsup_loss_numpy: 5.898049831390381|  0:01:27s\n",
            "epoch 73 | loss: 1.02412 | val_0_unsup_loss_numpy: 2.206429958343506|  0:01:28s\n",
            "epoch 74 | loss: 1.05638 | val_0_unsup_loss_numpy: 3.073889970779419|  0:01:29s\n",
            "epoch 75 | loss: 1.04553 | val_0_unsup_loss_numpy: 3.523750066757202|  0:01:29s\n",
            "epoch 76 | loss: 0.97594 | val_0_unsup_loss_numpy: 1.9549599885940552|  0:01:30s\n",
            "epoch 77 | loss: 0.97827 | val_0_unsup_loss_numpy: 3.568769931793213|  0:01:31s\n",
            "epoch 78 | loss: 1.01295 | val_0_unsup_loss_numpy: 2.5017600059509277|  0:01:32s\n",
            "epoch 79 | loss: 1.02752 | val_0_unsup_loss_numpy: 2.573780059814453|  0:01:33s\n",
            "epoch 80 | loss: 1.00336 | val_0_unsup_loss_numpy: 3.432349920272827|  0:01:34s\n",
            "epoch 81 | loss: 1.03637 | val_0_unsup_loss_numpy: 3.072809934616089|  0:01:35s\n",
            "epoch 82 | loss: 1.13421 | val_0_unsup_loss_numpy: 4.118100166320801|  0:01:36s\n",
            "epoch 83 | loss: 0.9809  | val_0_unsup_loss_numpy: 2.464639902114868|  0:01:37s\n",
            "epoch 84 | loss: 0.9823  | val_0_unsup_loss_numpy: 4.4137701988220215|  0:01:38s\n",
            "epoch 85 | loss: 1.01143 | val_0_unsup_loss_numpy: 2.948280096054077|  0:01:39s\n",
            "epoch 86 | loss: 0.99308 | val_0_unsup_loss_numpy: 4.223659992218018|  0:01:40s\n",
            "epoch 87 | loss: 1.03199 | val_0_unsup_loss_numpy: 2.9285099506378174|  0:01:41s\n",
            "epoch 88 | loss: 1.00981 | val_0_unsup_loss_numpy: 1.3468899726867676|  0:01:41s\n",
            "epoch 89 | loss: 1.00197 | val_0_unsup_loss_numpy: 2.1995599269866943|  0:01:42s\n",
            "epoch 90 | loss: 1.00952 | val_0_unsup_loss_numpy: 1.9228099584579468|  0:01:43s\n",
            "epoch 91 | loss: 0.99533 | val_0_unsup_loss_numpy: 1.6670900583267212|  0:01:44s\n",
            "epoch 92 | loss: 0.98892 | val_0_unsup_loss_numpy: 2.4254798889160156|  0:01:45s\n",
            "epoch 93 | loss: 0.99878 | val_0_unsup_loss_numpy: 3.3025801181793213|  0:01:46s\n",
            "epoch 94 | loss: 1.0114  | val_0_unsup_loss_numpy: 4.193769931793213|  0:01:47s\n",
            "epoch 95 | loss: 1.01513 | val_0_unsup_loss_numpy: 3.661099910736084|  0:01:48s\n",
            "epoch 96 | loss: 1.06547 | val_0_unsup_loss_numpy: 6.467659950256348|  0:01:49s\n",
            "epoch 97 | loss: 1.01266 | val_0_unsup_loss_numpy: 7.13877010345459|  0:01:50s\n",
            "epoch 98 | loss: 0.98373 | val_0_unsup_loss_numpy: 5.7182297706604|  0:01:51s\n",
            "epoch 99 | loss: 0.98223 | val_0_unsup_loss_numpy: 5.138609886169434|  0:01:52s\n",
            "epoch 100| loss: 0.96604 | val_0_unsup_loss_numpy: 3.4359700679779053|  0:01:53s\n",
            "epoch 101| loss: 0.97838 | val_0_unsup_loss_numpy: 3.472909927368164|  0:01:54s\n",
            "epoch 102| loss: 0.97914 | val_0_unsup_loss_numpy: 1.7127699851989746|  0:01:55s\n",
            "epoch 103| loss: 0.98097 | val_0_unsup_loss_numpy: 3.024630069732666|  0:01:55s\n",
            "epoch 104| loss: 0.95203 | val_0_unsup_loss_numpy: 2.3324100971221924|  0:01:56s\n",
            "epoch 105| loss: 0.96397 | val_0_unsup_loss_numpy: 2.080970048904419|  0:01:57s\n",
            "epoch 106| loss: 0.97438 | val_0_unsup_loss_numpy: 2.5767099857330322|  0:01:58s\n",
            "epoch 107| loss: 0.96671 | val_0_unsup_loss_numpy: 3.9611198902130127|  0:01:59s\n",
            "epoch 108| loss: 1.01103 | val_0_unsup_loss_numpy: 2.2860300540924072|  0:02:00s\n",
            "epoch 109| loss: 0.95205 | val_0_unsup_loss_numpy: 1.8778799772262573|  0:02:01s\n",
            "epoch 110| loss: 0.98664 | val_0_unsup_loss_numpy: 1.8468300104141235|  0:02:02s\n",
            "epoch 111| loss: 0.98501 | val_0_unsup_loss_numpy: 1.9531300067901611|  0:02:03s\n",
            "epoch 112| loss: 0.95393 | val_0_unsup_loss_numpy: 2.749380111694336|  0:02:04s\n",
            "epoch 113| loss: 0.97201 | val_0_unsup_loss_numpy: 1.2582000494003296|  0:02:05s\n",
            "epoch 114| loss: 0.95625 | val_0_unsup_loss_numpy: 1.2351800203323364|  0:02:06s\n",
            "epoch 115| loss: 0.96608 | val_0_unsup_loss_numpy: 2.033220052719116|  0:02:07s\n",
            "epoch 116| loss: 1.00071 | val_0_unsup_loss_numpy: 1.3891199827194214|  0:02:07s\n",
            "epoch 117| loss: 0.98143 | val_0_unsup_loss_numpy: 2.828969955444336|  0:02:08s\n",
            "epoch 118| loss: 0.99915 | val_0_unsup_loss_numpy: 2.1559998989105225|  0:02:09s\n",
            "epoch 119| loss: 0.97922 | val_0_unsup_loss_numpy: 1.7526700496673584|  0:02:10s\n",
            "epoch 120| loss: 0.97638 | val_0_unsup_loss_numpy: 1.5625  |  0:02:11s\n",
            "epoch 121| loss: 0.97269 | val_0_unsup_loss_numpy: 5.7288899421691895|  0:02:12s\n",
            "epoch 122| loss: 0.96516 | val_0_unsup_loss_numpy: 2.587549924850464|  0:02:12s\n",
            "epoch 123| loss: 0.97426 | val_0_unsup_loss_numpy: 5.125830173492432|  0:02:13s\n",
            "epoch 124| loss: 0.95307 | val_0_unsup_loss_numpy: 2.180759906768799|  0:02:14s\n",
            "epoch 125| loss: 1.00338 | val_0_unsup_loss_numpy: 3.1314098834991455|  0:02:16s\n",
            "epoch 126| loss: 0.94454 | val_0_unsup_loss_numpy: 4.040830135345459|  0:02:17s\n",
            "epoch 127| loss: 0.94066 | val_0_unsup_loss_numpy: 2.429689884185791|  0:02:18s\n",
            "epoch 128| loss: 0.98402 | val_0_unsup_loss_numpy: 2.9002699851989746|  0:02:18s\n",
            "epoch 129| loss: 0.96178 | val_0_unsup_loss_numpy: 2.385010004043579|  0:02:19s\n",
            "epoch 130| loss: 0.9789  | val_0_unsup_loss_numpy: 1.8570799827575684|  0:02:20s\n",
            "epoch 131| loss: 0.94833 | val_0_unsup_loss_numpy: 3.059609889984131|  0:02:21s\n",
            "epoch 132| loss: 0.95838 | val_0_unsup_loss_numpy: 2.1568100452423096|  0:02:22s\n",
            "epoch 133| loss: 0.96436 | val_0_unsup_loss_numpy: 1.7192000150680542|  0:02:23s\n",
            "epoch 134| loss: 0.99538 | val_0_unsup_loss_numpy: 1.7434899806976318|  0:02:24s\n",
            "epoch 135| loss: 0.99599 | val_0_unsup_loss_numpy: 4.181250095367432|  0:02:25s\n",
            "epoch 136| loss: 0.9953  | val_0_unsup_loss_numpy: 2.5311999320983887|  0:02:25s\n",
            "epoch 137| loss: 0.96984 | val_0_unsup_loss_numpy: 1.4574099779129028|  0:02:26s\n",
            "epoch 138| loss: 0.99408 | val_0_unsup_loss_numpy: 1.7776600122451782|  0:02:27s\n",
            "epoch 139| loss: 0.94827 | val_0_unsup_loss_numpy: 1.8480600118637085|  0:02:29s\n",
            "epoch 140| loss: 0.94984 | val_0_unsup_loss_numpy: 1.5728000402450562|  0:02:30s\n",
            "epoch 141| loss: 0.95863 | val_0_unsup_loss_numpy: 2.3139400482177734|  0:02:31s\n",
            "epoch 142| loss: 0.93117 | val_0_unsup_loss_numpy: 1.1012500524520874|  0:02:31s\n",
            "epoch 143| loss: 0.93286 | val_0_unsup_loss_numpy: 2.4076900482177734|  0:02:32s\n",
            "epoch 144| loss: 0.94009 | val_0_unsup_loss_numpy: 2.142620086669922|  0:02:33s\n",
            "epoch 145| loss: 0.96986 | val_0_unsup_loss_numpy: 2.3264501094818115|  0:02:34s\n",
            "epoch 146| loss: 0.99948 | val_0_unsup_loss_numpy: 1.9922900199890137|  0:02:35s\n",
            "epoch 147| loss: 0.93036 | val_0_unsup_loss_numpy: 1.6240299940109253|  0:02:36s\n",
            "epoch 148| loss: 0.95252 | val_0_unsup_loss_numpy: 2.052449941635132|  0:02:37s\n",
            "epoch 149| loss: 0.94232 | val_0_unsup_loss_numpy: 2.3498599529266357|  0:02:37s\n",
            "epoch 150| loss: 0.95835 | val_0_unsup_loss_numpy: 4.512030124664307|  0:02:38s\n",
            "epoch 151| loss: 1.02269 | val_0_unsup_loss_numpy: 2.1290700435638428|  0:02:39s\n",
            "epoch 152| loss: 0.95712 | val_0_unsup_loss_numpy: 1.612969994544983|  0:02:40s\n",
            "epoch 153| loss: 0.94251 | val_0_unsup_loss_numpy: 1.1106499433517456|  0:02:41s\n",
            "epoch 154| loss: 1.0038  | val_0_unsup_loss_numpy: 1.2953200340270996|  0:02:43s\n",
            "epoch 155| loss: 1.00065 | val_0_unsup_loss_numpy: 2.686919927597046|  0:02:43s\n",
            "epoch 156| loss: 0.96906 | val_0_unsup_loss_numpy: 1.1905100345611572|  0:02:44s\n",
            "epoch 157| loss: 0.98799 | val_0_unsup_loss_numpy: 2.7005300521850586|  0:02:45s\n",
            "epoch 158| loss: 1.00869 | val_0_unsup_loss_numpy: 1.7377899885177612|  0:02:46s\n",
            "epoch 159| loss: 0.9518  | val_0_unsup_loss_numpy: 2.194960117340088|  0:02:47s\n",
            "epoch 160| loss: 0.95322 | val_0_unsup_loss_numpy: 1.5106699466705322|  0:02:48s\n",
            "epoch 161| loss: 0.97076 | val_0_unsup_loss_numpy: 1.3701800107955933|  0:02:49s\n",
            "epoch 162| loss: 0.98342 | val_0_unsup_loss_numpy: 1.8268200159072876|  0:02:49s\n",
            "epoch 163| loss: 0.97585 | val_0_unsup_loss_numpy: 1.7958799600601196|  0:02:50s\n",
            "epoch 164| loss: 0.93667 | val_0_unsup_loss_numpy: 1.3373099565505981|  0:02:51s\n",
            "epoch 165| loss: 0.90917 | val_0_unsup_loss_numpy: 1.4019700288772583|  0:02:52s\n",
            "epoch 166| loss: 0.95972 | val_0_unsup_loss_numpy: 1.784350037574768|  0:02:53s\n",
            "epoch 167| loss: 0.94268 | val_0_unsup_loss_numpy: 0.8661800026893616|  0:02:54s\n",
            "epoch 168| loss: 0.95985 | val_0_unsup_loss_numpy: 1.5092500448226929|  0:02:55s\n",
            "epoch 169| loss: 0.93232 | val_0_unsup_loss_numpy: 3.3147499561309814|  0:02:56s\n",
            "epoch 170| loss: 0.9786  | val_0_unsup_loss_numpy: 4.106840133666992|  0:02:57s\n",
            "epoch 171| loss: 0.95812 | val_0_unsup_loss_numpy: 1.2058900594711304|  0:02:58s\n",
            "epoch 172| loss: 0.93417 | val_0_unsup_loss_numpy: 1.6390700340270996|  0:02:59s\n",
            "epoch 173| loss: 0.96622 | val_0_unsup_loss_numpy: 6.386569976806641|  0:03:00s\n",
            "epoch 174| loss: 0.95796 | val_0_unsup_loss_numpy: 5.121829986572266|  0:03:00s\n",
            "epoch 175| loss: 0.95253 | val_0_unsup_loss_numpy: 2.634000062942505|  0:03:01s\n",
            "epoch 176| loss: 0.97361 | val_0_unsup_loss_numpy: 1.6136399507522583|  0:03:02s\n",
            "epoch 177| loss: 0.94583 | val_0_unsup_loss_numpy: 1.7574900388717651|  0:03:03s\n",
            "epoch 178| loss: 0.94797 | val_0_unsup_loss_numpy: 1.4257700443267822|  0:03:04s\n",
            "epoch 179| loss: 0.90308 | val_0_unsup_loss_numpy: 1.7034399509429932|  0:03:05s\n",
            "epoch 180| loss: 0.9422  | val_0_unsup_loss_numpy: 1.6061700582504272|  0:03:06s\n",
            "epoch 181| loss: 0.9398  | val_0_unsup_loss_numpy: 2.011090040206909|  0:03:07s\n",
            "epoch 182| loss: 0.96124 | val_0_unsup_loss_numpy: 3.0716300010681152|  0:03:08s\n",
            "epoch 183| loss: 0.96357 | val_0_unsup_loss_numpy: 2.4229400157928467|  0:03:09s\n",
            "epoch 184| loss: 0.98525 | val_0_unsup_loss_numpy: 1.7083799839019775|  0:03:10s\n",
            "epoch 185| loss: 0.98321 | val_0_unsup_loss_numpy: 3.9252500534057617|  0:03:11s\n",
            "epoch 186| loss: 0.97509 | val_0_unsup_loss_numpy: 3.6238598823547363|  0:03:12s\n",
            "epoch 187| loss: 0.95739 | val_0_unsup_loss_numpy: 1.171839952468872|  0:03:12s\n",
            "epoch 188| loss: 0.92366 | val_0_unsup_loss_numpy: 1.416260004043579|  0:03:13s\n",
            "epoch 189| loss: 0.94389 | val_0_unsup_loss_numpy: 1.3972599506378174|  0:03:14s\n",
            "epoch 190| loss: 0.92677 | val_0_unsup_loss_numpy: 0.8329600095748901|  0:03:15s\n",
            "epoch 191| loss: 0.96095 | val_0_unsup_loss_numpy: 0.9943900108337402|  0:03:16s\n",
            "epoch 192| loss: 1.00297 | val_0_unsup_loss_numpy: 2.0339601039886475|  0:03:17s\n",
            "epoch 193| loss: 0.95801 | val_0_unsup_loss_numpy: 2.1033198833465576|  0:03:17s\n",
            "epoch 194| loss: 0.96662 | val_0_unsup_loss_numpy: 2.409169912338257|  0:03:18s\n",
            "epoch 195| loss: 0.9828  | val_0_unsup_loss_numpy: 2.070810079574585|  0:03:20s\n",
            "epoch 196| loss: 0.96697 | val_0_unsup_loss_numpy: 2.035059928894043|  0:03:21s\n",
            "epoch 197| loss: 0.9513  | val_0_unsup_loss_numpy: 1.3923200368881226|  0:03:22s\n",
            "epoch 198| loss: 0.92016 | val_0_unsup_loss_numpy: 0.9362900257110596|  0:03:23s\n",
            "epoch 199| loss: 0.93276 | val_0_unsup_loss_numpy: 1.2797600030899048|  0:03:23s\n",
            "epoch 200| loss: 0.93659 | val_0_unsup_loss_numpy: 0.9290099740028381|  0:03:24s\n",
            "epoch 201| loss: 0.95179 | val_0_unsup_loss_numpy: 1.2228800058364868|  0:03:25s\n",
            "epoch 202| loss: 0.96227 | val_0_unsup_loss_numpy: 1.2627700567245483|  0:03:26s\n",
            "epoch 203| loss: 0.96917 | val_0_unsup_loss_numpy: 0.9638000130653381|  0:03:27s\n",
            "epoch 204| loss: 0.92469 | val_0_unsup_loss_numpy: 55.167518615722656|  0:03:28s\n",
            "epoch 205| loss: 0.91867 | val_0_unsup_loss_numpy: 0.9883800148963928|  0:03:29s\n",
            "epoch 206| loss: 0.96156 | val_0_unsup_loss_numpy: 2.2484800815582275|  0:03:29s\n",
            "epoch 207| loss: 0.93962 | val_0_unsup_loss_numpy: 1.411389946937561|  0:03:30s\n",
            "epoch 208| loss: 0.97441 | val_0_unsup_loss_numpy: 1.254830002784729|  0:03:31s\n",
            "epoch 209| loss: 0.99362 | val_0_unsup_loss_numpy: 1.0943200588226318|  0:03:33s\n",
            "epoch 210| loss: 0.92306 | val_0_unsup_loss_numpy: 0.9751499891281128|  0:03:34s\n",
            "epoch 211| loss: 0.92578 | val_0_unsup_loss_numpy: 1.3146799802780151|  0:03:35s\n",
            "epoch 212| loss: 0.92144 | val_0_unsup_loss_numpy: 1.9501399993896484|  0:03:36s\n",
            "epoch 213| loss: 0.99507 | val_0_unsup_loss_numpy: 1.870710015296936|  0:03:37s\n",
            "epoch 214| loss: 0.95681 | val_0_unsup_loss_numpy: 0.9798700213432312|  0:03:37s\n",
            "epoch 215| loss: 0.93764 | val_0_unsup_loss_numpy: 1.3189799785614014|  0:03:38s\n",
            "epoch 216| loss: 0.90163 | val_0_unsup_loss_numpy: 1.0336500406265259|  0:03:39s\n",
            "epoch 217| loss: 0.9297  | val_0_unsup_loss_numpy: 2.0560100078582764|  0:03:40s\n",
            "epoch 218| loss: 0.92043 | val_0_unsup_loss_numpy: 1.1875200271606445|  0:03:41s\n",
            "epoch 219| loss: 0.94781 | val_0_unsup_loss_numpy: 1.440019965171814|  0:03:42s\n",
            "epoch 220| loss: 0.96053 | val_0_unsup_loss_numpy: 1.3330600261688232|  0:03:43s\n",
            "epoch 221| loss: 0.92037 | val_0_unsup_loss_numpy: 1.100890040397644|  0:03:44s\n",
            "epoch 222| loss: 0.94057 | val_0_unsup_loss_numpy: 1.0697599649429321|  0:03:45s\n",
            "epoch 223| loss: 0.9662  | val_0_unsup_loss_numpy: 1.0575900077819824|  0:03:46s\n",
            "epoch 224| loss: 0.89568 | val_0_unsup_loss_numpy: 0.8180199861526489|  0:03:47s\n",
            "epoch 225| loss: 0.94445 | val_0_unsup_loss_numpy: 0.8621399998664856|  0:03:48s\n",
            "epoch 226| loss: 0.95931 | val_0_unsup_loss_numpy: 1.0441800355911255|  0:03:49s\n",
            "epoch 227| loss: 0.97343 | val_0_unsup_loss_numpy: 1.1237499713897705|  0:03:50s\n",
            "epoch 228| loss: 0.99422 | val_0_unsup_loss_numpy: 0.9446399807929993|  0:03:51s\n",
            "epoch 229| loss: 0.93064 | val_0_unsup_loss_numpy: 1.4541499614715576|  0:03:52s\n",
            "epoch 230| loss: 0.92614 | val_0_unsup_loss_numpy: 1.387969970703125|  0:03:53s\n",
            "epoch 231| loss: 0.9206  | val_0_unsup_loss_numpy: 2.4073901176452637|  0:03:53s\n",
            "epoch 232| loss: 0.96639 | val_0_unsup_loss_numpy: 1.1717599630355835|  0:03:54s\n",
            "epoch 233| loss: 0.90013 | val_0_unsup_loss_numpy: 0.9957500100135803|  0:03:55s\n",
            "epoch 234| loss: 0.93945 | val_0_unsup_loss_numpy: 1.4233200550079346|  0:03:56s\n",
            "epoch 235| loss: 0.94925 | val_0_unsup_loss_numpy: 0.8621799945831299|  0:03:59s\n",
            "epoch 236| loss: 0.93533 | val_0_unsup_loss_numpy: 1.0741499662399292|  0:04:01s\n",
            "epoch 237| loss: 0.93854 | val_0_unsup_loss_numpy: 2.4035799503326416|  0:04:03s\n",
            "epoch 238| loss: 0.89415 | val_0_unsup_loss_numpy: 1.513069987297058|  0:04:05s\n",
            "epoch 239| loss: 0.92814 | val_0_unsup_loss_numpy: 2.0381999015808105|  0:04:06s\n",
            "epoch 240| loss: 0.92219 | val_0_unsup_loss_numpy: 2.590670108795166|  0:04:07s\n",
            "epoch 241| loss: 0.93136 | val_0_unsup_loss_numpy: 2.2759599685668945|  0:04:08s\n",
            "epoch 242| loss: 0.92486 | val_0_unsup_loss_numpy: 3.492609977722168|  0:04:09s\n",
            "epoch 243| loss: 0.94625 | val_0_unsup_loss_numpy: 2.9884800910949707|  0:04:10s\n",
            "epoch 244| loss: 0.94459 | val_0_unsup_loss_numpy: 4.24560022354126|  0:04:10s\n",
            "epoch 245| loss: 0.93939 | val_0_unsup_loss_numpy: 1.5126800537109375|  0:04:12s\n",
            "epoch 246| loss: 0.98898 | val_0_unsup_loss_numpy: 3.457819938659668|  0:04:13s\n",
            "epoch 247| loss: 0.94873 | val_0_unsup_loss_numpy: 1.894320011138916|  0:04:14s\n",
            "epoch 248| loss: 0.87735 | val_0_unsup_loss_numpy: 1.4816499948501587|  0:04:15s\n",
            "epoch 249| loss: 0.92425 | val_0_unsup_loss_numpy: 0.7379099726676941|  0:04:17s\n",
            "epoch 250| loss: 0.93668 | val_0_unsup_loss_numpy: 0.9786800146102905|  0:04:18s\n",
            "epoch 251| loss: 0.91283 | val_0_unsup_loss_numpy: 2.0491700172424316|  0:04:19s\n",
            "epoch 252| loss: 0.97617 | val_0_unsup_loss_numpy: 0.9217699766159058|  0:04:21s\n",
            "epoch 253| loss: 0.9361  | val_0_unsup_loss_numpy: 0.7584400177001953|  0:04:22s\n",
            "epoch 254| loss: 0.94098 | val_0_unsup_loss_numpy: 0.8773000240325928|  0:04:23s\n",
            "epoch 255| loss: 0.93109 | val_0_unsup_loss_numpy: 1.1394699811935425|  0:04:24s\n",
            "epoch 256| loss: 0.90395 | val_0_unsup_loss_numpy: 1.7662299871444702|  0:04:25s\n",
            "epoch 257| loss: 0.95674 | val_0_unsup_loss_numpy: 1.2294600009918213|  0:04:27s\n",
            "epoch 258| loss: 0.9606  | val_0_unsup_loss_numpy: 0.89055997133255|  0:04:27s\n",
            "epoch 259| loss: 0.93633 | val_0_unsup_loss_numpy: 1.0223100185394287|  0:04:28s\n",
            "epoch 260| loss: 0.93265 | val_0_unsup_loss_numpy: 0.9959800243377686|  0:04:29s\n",
            "epoch 261| loss: 0.95008 | val_0_unsup_loss_numpy: 1.6811399459838867|  0:04:30s\n",
            "epoch 262| loss: 0.89237 | val_0_unsup_loss_numpy: 0.8184099793434143|  0:04:31s\n",
            "epoch 263| loss: 0.9253  | val_0_unsup_loss_numpy: 1.136680006980896|  0:04:32s\n",
            "epoch 264| loss: 0.93444 | val_0_unsup_loss_numpy: 1.1648900508880615|  0:04:33s\n",
            "epoch 265| loss: 0.92015 | val_0_unsup_loss_numpy: 0.7674499750137329|  0:04:33s\n",
            "epoch 266| loss: 0.91671 | val_0_unsup_loss_numpy: 1.225059986114502|  0:04:34s\n",
            "epoch 267| loss: 0.91991 | val_0_unsup_loss_numpy: 0.8293600082397461|  0:04:35s\n",
            "epoch 268| loss: 0.91284 | val_0_unsup_loss_numpy: 1.4025100469589233|  0:04:36s\n",
            "epoch 269| loss: 0.91113 | val_0_unsup_loss_numpy: 1.4673000574111938|  0:04:37s\n",
            "epoch 270| loss: 0.93518 | val_0_unsup_loss_numpy: 1.2815799713134766|  0:04:38s\n",
            "epoch 271| loss: 0.92082 | val_0_unsup_loss_numpy: 1.3215399980545044|  0:04:39s\n",
            "epoch 272| loss: 0.94605 | val_0_unsup_loss_numpy: 0.8621399998664856|  0:04:40s\n",
            "epoch 273| loss: 0.91858 | val_0_unsup_loss_numpy: 1.3683300018310547|  0:04:41s\n",
            "epoch 274| loss: 0.92827 | val_0_unsup_loss_numpy: 2.46370005607605|  0:04:42s\n",
            "epoch 275| loss: 1.03347 | val_0_unsup_loss_numpy: 1.2810300588607788|  0:04:43s\n",
            "epoch 276| loss: 0.94369 | val_0_unsup_loss_numpy: 0.9792600274085999|  0:04:44s\n",
            "epoch 277| loss: 0.93873 | val_0_unsup_loss_numpy: 0.9304199814796448|  0:04:45s\n",
            "epoch 278| loss: 0.95698 | val_0_unsup_loss_numpy: 0.9448099732398987|  0:04:45s\n",
            "epoch 279| loss: 0.95091 | val_0_unsup_loss_numpy: 1.4858200550079346|  0:04:46s\n",
            "epoch 280| loss: 0.94106 | val_0_unsup_loss_numpy: 1.3953200578689575|  0:04:47s\n",
            "epoch 281| loss: 0.91586 | val_0_unsup_loss_numpy: 0.8679500222206116|  0:04:48s\n",
            "epoch 282| loss: 0.96735 | val_0_unsup_loss_numpy: 0.8924800157546997|  0:04:49s\n",
            "epoch 283| loss: 0.93331 | val_0_unsup_loss_numpy: 0.9684399962425232|  0:04:50s\n",
            "epoch 284| loss: 0.92272 | val_0_unsup_loss_numpy: 0.9303299784660339|  0:04:51s\n",
            "\n",
            "Early stopping occurred at epoch 284 with best_epoch = 249 and best_val_0_unsup_loss_numpy = 0.7379099726676941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unsupervised_encoder = unsupervised_model.network.encoder\n",
        "unsupervised_decoder = unsupervised_model.network.decoder"
      ],
      "metadata": {
        "id": "8h3faFrKn9PX"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_data = torch.tensor(X_train).to(torch.float32).to(\"cuda\")"
      ],
      "metadata": {
        "id": "_PV5M0xcq5ZA"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noise(col, row, device = \"cuda\"):\n",
        "  noise = [torch.tensor(np.random.rand(col, row)).to(torch.float32).to(device) for _ in range(3)]\n",
        "  return noise\n",
        "noise = create_noise(3, 8,)"
      ],
      "metadata": {
        "id": "0AUhdyg5s4Ws"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, encoder, features):\n",
        "    super().__init__()\n",
        "    for param in encoder.parameters():\n",
        "      param.requires_grad = False\n",
        "    self.encoder = encoder\n",
        "    self.features = features #decoderに通した後の出力のrow数を意味する\n",
        "    self.ffn = nn.Linear(self.features*3, self.features, bias = False)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear = nn.Linear(self.features, 2, bias = False)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  def forward(self, table_data):\n",
        "    extracted_data, _ = self.encoder(table_data)\n",
        "    x = extracted_data[0]\n",
        "    for ext_data in extracted_data[1:]:\n",
        "      x = torch.concatenate([x, ext_data], dim = 1)\n",
        "    x = self.ffn(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.linear(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "tNJBLJxJtyF0"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc = Discriminator(unsupervised_encoder, 8).to(\"cuda\")\n",
        "gene = unsupervised_decoder.to(\"cuda\")\n",
        "optimizerD = optim.Adam(disc.parameters(), lr = 1e-4)\n",
        "optimizerG = optim.Adam(gene.parameters(), lr = 1e-4)\n",
        "col = 16512\n",
        "row = 8\n",
        "def trainTGAN(optimizerD, optimizerG, real_data, device = \"cuda\"):\n",
        "  #まず識別器のモデルを改善した後に生成器のモデルを改善する\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizerD.zero_grad()\n",
        "    batch_size = real_data.size(0)\n",
        "    real_proba = disc(real_data) #データの形状が合わない時はforward内部で入力ように整形変更することを想定して制作。\n",
        "    real_label = torch.ones_like(real_proba).to(device)\n",
        "    real_label[:,0] = 0\n",
        "    D_loss_real = criterion(real_proba, real_label)\n",
        "    input_z = create_noise(col, row,)\n",
        "    fake_data = gene(input_z)\n",
        "    fake_proba = disc(fake_data)\n",
        "    fake_label = torch.ones_like(fake_proba).to(device)\n",
        "    fake_label[:,1] = 0\n",
        "    D_loss_fake = criterion(fake_proba,fake_label)\n",
        "    D_loss = D_loss_fake + D_loss_real\n",
        "    D_loss.backward()\n",
        "    optimizerD.step()\n",
        "    #D_lossのところでGenerate Modelのパラメータの勾配も計算されている為、Generate Modelに関する勾配はここで初期化を行う\n",
        "    optimizerG.zero_grad()\n",
        "    input_z = create_noise(col, row,)\n",
        "    fake_data = gene(input_z)\n",
        "    fake_proba = disc(fake_data)\n",
        "    real_label = torch.ones_like(fake_proba).to(device)\n",
        "    real_label[:,0] = 0 #ラベルが1になるように(騙すように)訓練するので、ラベルは1を予測するように作る\n",
        "    G_loss = criterion(fake_proba,real_label)\n",
        "    G_loss.backward()\n",
        "    optimizerG.step()\n",
        "    return D_loss.detach().item(), G_loss.detach().item()"
      ],
      "metadata": {
        "id": "SfrkGDW8tYSm"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 750\n",
        "D_losses = []\n",
        "G_losses = []\n",
        "from tqdm import tqdm\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  D_loss, G_loss = trainTGAN(optimizerD, optimizerG, batch_data, device = \"cuda\")\n",
        "  if epoch % 10 == 0:\n",
        "        print(f\"Discriminator Loss: {D_loss},Generater Loss: {G_loss}\")\n",
        "print(f\"Discriminator Loss: {D_loss},Generater Loss: {G_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gpRL6xIwLuf",
        "outputId": "0d1d1296-8055-4929-927e-bef0158a5bbc"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/750 [00:00<08:22,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3839466571807861,Generater Loss: 0.7142834067344666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 11/750 [00:07<08:02,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3837580680847168,Generater Loss: 0.7140856385231018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 21/750 [00:14<08:23,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3836052417755127,Generater Loss: 0.7139275074005127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 31/750 [00:21<09:11,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3835499286651611,Generater Loss: 0.7135618925094604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 41/750 [00:29<08:05,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.383561134338379,Generater Loss: 0.7133122086524963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 51/750 [00:37<11:50,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3836033344268799,Generater Loss: 0.7130866050720215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 61/750 [00:45<08:36,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3836809396743774,Generater Loss: 0.7128545641899109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 71/750 [00:52<08:05,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3837584257125854,Generater Loss: 0.7127472162246704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 81/750 [00:59<07:16,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3837575912475586,Generater Loss: 0.7124091982841492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 91/750 [01:06<07:30,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3836590051651,Generater Loss: 0.7121677994728088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 101/750 [01:13<07:42,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.38375723361969,Generater Loss: 0.7117449641227722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 111/750 [01:21<07:12,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3837108612060547,Generater Loss: 0.711113452911377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 121/750 [01:28<08:57,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3835926055908203,Generater Loss: 0.7105957269668579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 131/750 [01:35<06:45,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3834363222122192,Generater Loss: 0.7100093364715576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 141/750 [01:42<08:15,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3832476139068604,Generater Loss: 0.7093432545661926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 151/750 [01:49<06:30,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3830084800720215,Generater Loss: 0.7088114619255066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 161/750 [01:57<07:22,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3826565742492676,Generater Loss: 0.7081483006477356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 171/750 [02:03<06:19,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3822720050811768,Generater Loss: 0.7076442241668701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 181/750 [02:11<06:40,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3817880153656006,Generater Loss: 0.7071371078491211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 191/750 [02:18<06:04,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.381199836730957,Generater Loss: 0.7066367864608765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 201/750 [02:25<06:11,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3805546760559082,Generater Loss: 0.7062922716140747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 211/750 [02:32<07:27,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3797776699066162,Generater Loss: 0.7059836983680725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 221/750 [02:40<05:55,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3790178298950195,Generater Loss: 0.7056843042373657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 231/750 [02:56<13:47,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.378110647201538,Generater Loss: 0.7054736018180847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 241/750 [03:08<08:38,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.377143144607544,Generater Loss: 0.7054073214530945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 251/750 [03:16<06:10,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3759753704071045,Generater Loss: 0.7053278088569641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 261/750 [03:22<05:25,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3748116493225098,Generater Loss: 0.7053204774856567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 271/750 [03:30<05:42,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3735013008117676,Generater Loss: 0.7053980827331543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 281/750 [03:38<06:06,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.372166633605957,Generater Loss: 0.7055639028549194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 291/750 [03:46<05:35,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3707094192504883,Generater Loss: 0.7056765556335449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 301/750 [03:54<06:05,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3692514896392822,Generater Loss: 0.7058332562446594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████▏     | 311/750 [04:00<04:51,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3677680492401123,Generater Loss: 0.7060628533363342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 321/750 [04:08<05:15,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3662712574005127,Generater Loss: 0.7061575651168823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 331/750 [04:15<04:34,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3648622035980225,Generater Loss: 0.7061968445777893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 341/750 [04:22<04:42,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3635368347167969,Generater Loss: 0.7061349749565125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 351/750 [04:29<04:28,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3623838424682617,Generater Loss: 0.705812394618988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 361/750 [04:37<04:27,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.361501932144165,Generater Loss: 0.7051694989204407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 371/750 [04:44<06:06,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.361065149307251,Generater Loss: 0.7040795683860779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 381/750 [04:51<04:05,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.361335277557373,Generater Loss: 0.7023307085037231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 391/750 [05:00<05:57,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3622257709503174,Generater Loss: 0.7000322937965393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 401/750 [05:11<07:31,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3642643690109253,Generater Loss: 0.6971389055252075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 411/750 [05:21<05:10,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3669568300247192,Generater Loss: 0.6932492256164551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 421/750 [05:29<03:50,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3708505630493164,Generater Loss: 0.6887689828872681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 431/750 [05:37<04:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.37530517578125,Generater Loss: 0.6838189363479614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 441/750 [05:47<04:17,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3799173831939697,Generater Loss: 0.6786330938339233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 451/750 [06:00<05:55,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3852934837341309,Generater Loss: 0.6734722852706909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 461/750 [06:10<04:35,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.390136480331421,Generater Loss: 0.6684565544128418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 471/750 [06:20<04:10,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3944728374481201,Generater Loss: 0.6643355488777161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 481/750 [06:29<03:57,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3978028297424316,Generater Loss: 0.6609973907470703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 491/750 [06:38<03:29,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4001094102859497,Generater Loss: 0.6590545773506165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 501/750 [06:46<03:18,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4015097618103027,Generater Loss: 0.6575215458869934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 511/750 [06:52<02:34,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4026846885681152,Generater Loss: 0.6565098762512207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 521/750 [07:00<02:48,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4041911363601685,Generater Loss: 0.6549742221832275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 531/750 [07:06<02:26,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4067192077636719,Generater Loss: 0.6532664895057678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 541/750 [07:14<02:23,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4092166423797607,Generater Loss: 0.6516748666763306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 551/750 [07:21<02:09,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.411320447921753,Generater Loss: 0.6501348614692688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 561/750 [07:28<02:08,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4129728078842163,Generater Loss: 0.6493032574653625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 571/750 [07:36<02:28,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.413665533065796,Generater Loss: 0.6492605209350586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 581/750 [07:43<01:53,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4138044118881226,Generater Loss: 0.6498432755470276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 591/750 [07:50<02:13,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.413116693496704,Generater Loss: 0.6510093808174133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 601/750 [07:57<01:39,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4119908809661865,Generater Loss: 0.6526111364364624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 611/750 [08:05<01:42,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4102771282196045,Generater Loss: 0.6546124815940857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 621/750 [08:12<01:27,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4081785678863525,Generater Loss: 0.6569646596908569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 631/750 [08:19<01:21,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4057502746582031,Generater Loss: 0.6594735980033875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 641/750 [08:26<01:14,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4030691385269165,Generater Loss: 0.6622321605682373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 651/750 [08:34<01:07,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.4001429080963135,Generater Loss: 0.6650701761245728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 661/750 [08:41<01:17,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3972176313400269,Generater Loss: 0.6679739356040955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 671/750 [08:48<00:53,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3942019939422607,Generater Loss: 0.6708752512931824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 681/750 [08:56<00:55,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3912725448608398,Generater Loss: 0.6736670136451721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 691/750 [09:02<00:39,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3885314464569092,Generater Loss: 0.6762608885765076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 701/750 [09:10<00:36,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3864160776138306,Generater Loss: 0.6783101558685303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 711/750 [09:17<00:25,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3851897716522217,Generater Loss: 0.6798689365386963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 721/750 [09:24<00:20,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3845922946929932,Generater Loss: 0.6814018487930298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 731/750 [09:31<00:12,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3841367959976196,Generater Loss: 0.6831267476081848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 741/750 [09:38<00:06,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3833162784576416,Generater Loss: 0.6853542923927307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [09:46<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator Loss: 1.3823182582855225,Generater Loss: 0.6878888010978699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb_rg = lgb.LGBMRegressor(max_depth = 100, n_estimators = 100)"
      ],
      "metadata": {
        "id": "KMpSfTayzaXc"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_rg.fit(X_train[:,:-1], X_train[:,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "h5gQCHlt2Y8J",
        "outputId": "fadd7dc8-d2f3-4fa6-f6e2-abf50fda5a76"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1837\n",
            "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 2.020670\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(max_depth=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(max_depth=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(max_depth=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = lgb_rg.predict(X_test[:,:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rdOrEC12dLM",
        "outputId": "f66d0691-a789-457c-cdcc-55b76e297375"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(pred - X_test[:,-1]).std()\n",
        "#元のデータでの予測"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asNIBy282fES",
        "outputId": "3f3a66b1-04d5-4bd1-c981-4b1c3d051115"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4670865970792997"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_z = create_noise(col, row,)\n",
        "aug_data = gene(input_z).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "8JPgvVtD24LM"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_rg = lgb.LGBMRegressor(max_depth = 100, n_estimators = 100)\n",
        "lgb_rg.fit(aug_data[:,:-1], aug_data[:,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "aefKTc8x3HQV",
        "outputId": "b38cc73e-b382-47ed-f143-5e0872b4280d"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.403901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(max_depth=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(max_depth=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(max_depth=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = lgb_rg.predict(X_test[:,:-1])\n",
        "(pred - X_test[:,-1]).std()\n",
        "#増殖したデータのみでの予測"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGSmjpXO3Xl_",
        "outputId": "7fde6d80-2a8c-4c43-f70e-d38ef8de23ce"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6502803279115924"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#さらに増やす\n",
        "input_z = create_noise(30000, row,)\n",
        "aug_data = gene(input_z).detach().cpu().numpy()\n",
        "lgb_rg = lgb.LGBMRegressor(max_depth = 100, n_estimators = 100)\n",
        "lgb_rg.fit(aug_data[:,:-1], aug_data[:,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "5y8y7XKl6ZGG",
        "outputId": "a24050ea-3e47-48a1-ea79-fbcf87f1fc30"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002201 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.403906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(max_depth=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(max_depth=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(max_depth=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = lgb_rg.predict(X_test[:,:-1])\n",
        "(pred - X_test[:,-1]).std()\n",
        "#増殖したデータのみでの予測"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qCWAbQr6fpI",
        "outputId": "d027ffaf-bb83-468a-8674-39c930b84e22"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6483851207250447"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#さらに増やす\n",
        "input_z = create_noise(50000, row,)\n",
        "aug_data = gene(input_z).detach().cpu().numpy()\n",
        "lgb_rg = lgb.LGBMRegressor(max_depth = 100, n_estimators = 100)\n",
        "lgb_rg.fit(aug_data[:,:-1], aug_data[:,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "v_9luhO27XDi",
        "outputId": "6376af7a-15ff-4b8b-e3ca-6c2fc67e26ed"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.404857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(max_depth=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(max_depth=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(max_depth=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = lgb_rg.predict(X_test[:,:-1])\n",
        "(pred - X_test[:,-1]).std()\n",
        "#増殖したデータのみでの予測"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAwtJTmV7ZlI",
        "outputId": "74ec3f2c-2555-4677-f6c6-d8786d443443"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6511483299173231"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    }
  ]
}